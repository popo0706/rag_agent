# ==============================================================
# 【概要】
# このスクリプトは LangChain を利用して
# 「料理名 → レシピ案」を生成する最小サンプルです。
# 処理の流れは次の５ステップです。
#   ① 会話用プロンプトテンプレートを作成する
#   ② OpenAI LLM（gpt-4.1-nano）を初期化する
#   ③ テンプレートと LLM をチェーンで接続する
#   ④ ユーザ入力（dish）を渡して応答を取得する
#   ⑤ 生成されたレシピを表示する
# temperature=0 なので毎回同じ出力になり、
# テストやデモに扱いやすい構成になっています。
# ==============================================================


from langchain_core.prompts import (
    ChatPromptTemplate,
)  # ChatGPT 形式のプロンプトを簡単に組み立てるクラス
from langchain_openai import (
    ChatOpenAI,
)  # OpenAI Chat モデルを Python オブジェクトとして扱うラッパー

# ──────────────────────────────────────────────
# ① プロンプトテンプレートの作成
#    ChatPromptTemplate.from_messages() に
#    (role, content) のタプルをリストで渡すと、
#    会話形式のテンプレートが生成される。
#    {dish} は後から実際の料理名で置換されるプレースホルダ。
# ──────────────────────────────────────────────
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "ユーザが入力したレシピを考えてください。",
        ),  # AI に課す「役割」の指示
        ("human", "{dish}"),  # ユーザ発話部分（可変）
    ]
)

# ──────────────────────────────────────────────
# ② LLM(大規模言語モデル) オブジェクトの生成
#    model       : gpt-4.1-nano（軽量モデル）
#    temperature : 0 で決定論的出力（同じ入力 → 同じ応答）
# ──────────────────────────────────────────────
model = ChatOpenAI(model="gpt-4.1-nano", temperature=0)

# ──────────────────────────────────────────────
# ③ プロンプトとモデルをパイプ (|) で連結してチェーンを構築
#    prompt | model は「作成したメッセージ → LLM 呼び出し」
#    の一連処理をまとめた LangChain 独自のシンタックス糖衣。
# ──────────────────────────────────────────────
chain = prompt | model

# ──────────────────────────────────────────────
# ④ チェーンを実行して応答を取得
#    chain.invoke() に dict を渡すと、テンプレート中の
#    {dish} が実際の値 "カレー" に置換される。
#    戻り値は llm形式の AIMessage オブジェクト。
# ──────────────────────────────────────────────
ai_message = chain.invoke({"dish": "カレー"})

# ──────────────────────────────────────────────
# ⑤ 生成されたレシピ (メッセージ本文) を表示
#    AIMessage.content にレシピ文字列が格納されている。
# ──────────────────────────────────────────────
print(ai_message.content)
